**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 â€“ Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group \#5:        |
| ------------------|
| Ethan Rigby       |
| Labib Afsar Ahmed |
| Mohammed Alshoura |
| Danielle Jourdain |

# 1 Introduction

This lab focused on building our knowledge of unit testing from the previous lab. We were given the chance to reanalyze the same code from the second lab while given a chance to improve upon the tests made. The main difference between lab 2 and 3 was: rather than using a blackbox approach to unit testing, this lab allowed us to view the actual code and create unit tests based on functions (whitebox testing) while also allowing us to introduce a test suite. This means that our test cases can be more accurate to what is needed to be tested by the function than blackbox testing allowed for. Thus, allowing us to more thoroughly create tests.

# 2 Manual data-flow coverage calculations for X and Y methods

## Intersects in Range Data-flow coverage

For the method intersects in Range. The Data flow graph is as follows:
<img src="coverage_screenshots/Intersects_DFG.png" alt="coverage_screenshots/Intersects_DFG.png"/>

Each node is a statement, and the def-use sets are shown above each node, the DU-pairs for the variables are as follows:

| Variable (V) | Defined at node (n) | dcu(v, n) | dpu(v,n)       |
|--------------|---------------------|-----------|----------------|
| b0           | 1                   | {4}       | {[2,3], [2,4]} |
| b1           | 1                   | {3,4}     |                |
| Total:       |                     | 3         | 2              |

CU = 3      ,    PU = 2 <br>
CU<sub>c</sub> = 3  <br>
PU<sub>c</sub> = 2 <br>CU<sub>c</sub>, and PU<sub>c</sub> were found in the following tests: <br>(intersectsRangeFullyOverlapsSpecifiedRange, and            intersectsRangePartiallyOverlapingSpecifiedRange)

### There were no infeasible cases

coverage is found by: <br>
(2+3)/(2+3) = 100%

## calculateColumnTotal in DataUtilities Data-flow coverage

For the method intersects in Range. The Data flow graph is as follows:
<img src="coverage_screenshots/CalculateColumnTotal_Dataflow.png" alt="coverage_screenshots/CalculateColumnTotal_Dataflow.png"/>

The def-use sets are shown to the right each node, the DU-pairs for the variables are as follows:

| Variable (V)   | Defined at node (n) | dcu(v, n) | dpu(v,n)        |
|----------------|---------------------|-----------|---------------- |
| data           | 1                   | {1,3,7}   |                 |
| column         | 1                   | {3,7}     |                 |
| total          | 1,5,9               | {5,9,10}  |                 |
| rowCount       | 1                   |           |{2,6}            |
| r              | 2                   | {2,3}     |{[2,3], [2,6]}   |
| n              | 3                   | {5}       |{[4,2], [4,5]}   |
| r2 (infeasible)| 6                   | {6,7}     |{[6,7], [6,10]}  |
| n (infeasible) | 7                   | {9}       |{[8,6],[8,9]}    |
| Total:         |                     | 14        | 10              |

## Nodes 6-9 are infeasible since r2 is defined to be 0 at line 133, and rowCount is always >= 0, so the second for loop is never entered

CU = 14      ,    PU = 10 <br>
CU<sub>f</sub> = 6  <br>
PU<sub>f</sub> = 4 <br>
CU<sub>c</sub> = 8  <br>
PU<sub>c</sub> = 5 <br>CU<sub>c</sub>, and PU<sub>c</sub> were found in the following tests: <br>(calculateColumnTotalForTwoValues,            calculateColumnTotalReturnsZeroForInvalidValue, and calculateColumnTotalReturnsZeroForEmptyValue2D)

### The feasible Path missed is [3,4,5] since we don't test what happens when data with a valid rowcount has null for values

coverage is found by:<br>
(8+5)/((14+10)-(6+4)) = 92.85%

# 3 A detailed description of the testing strategy for the new unit test

To develop new unit tests, we first developed a plan to ensure our test suite completed all the metrics that were required. To do this, we first began by looking at the method coverage for each class. We noted what the current value was from the Eclipse EclEmma tool, and noted how many more methods we would need to develop tests for to hit the 60% coverage goal mentioned in the assignment. We then wrote one test method to cover each of these missed methods to reach our goal.

After we achieved our method coverage goal, we moved on to looking at the branch coverage for each method. We began by running the branch coverage tool in EclEmma. We noted these values, and also looked at the source code. Then we looked at the possible paths for the method, as well as the tests we had already written and what paths they covered. We then wrote new cases to cover all of the missing branches that were possible to reach. there were some branches that were not possible to reach, which were left un-tested. After this was done, we re-ran the coverage tool to ensure we had covered more branches and reached our goal of 70%.

After completing the test cases to improve branch coverage, we finally moved on to statement coverage. To check our current progress, we used the line coverage option in EclEmma. We then examined the results in detail to check which methods had lines that had not been tested, then wrote methods to ensure these got covered to. After this was done, we re-ran the coverage tool to ensure our goal of 90% statement coverage had been acheived.

Overall by using this test development strategy, we developed 32 more test cases for the Range class and 25 for the DataUtilities class.

# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

## 4.1 Range expandToInclude

This method had been tested in Assignment 2. We began the improvement by first running EclEmma to see the current branch coverage of this method. We found that we had acheived 83.3% branch coverage already. To improve this, we looked at the source code to see what branch had been missed. We noticed that the only branch we had missed was the branch that has a null range as the input. To increase the coverage, we designed one new test case: expandToIncludeStartingRangeNull which passed a null range into the method to test the output. By creating this test case, we increased branch coverage to 100%. By increasing the branch coverage, we also brough statement coverage up to 100% for expandToInclude.

## 4.2 Range combineIgnoringNaN

This method had not been tested during Assignment 2. To begin, we first read through the documentation on what the method should do. After we understood how the method was intended to work, we looked at the source code to see how the function had been implemented. We noticed there were 14 possible branches. We ended up creating 8 test cases for this class. With these 8 methods we were able to cover 12 of the branches. The remaining 2 braches are unreachable, since they require a range to both be null and include one or more NaN values. Since it is impossible for a range to be both null and have values, these cannot be reached. After developing our test cases, we achieved 85.7% branch coverage and 100% statement coverage for this method.

## 4.3 DataUtilities calculateColumnTotal(Values2D data, int column)

This method was tested in Assignment 2. To improve it, we ran EclEmma to determine the coverage of this method. We found that we only had 50% branch coverage from the previous assignment. To improve this, we looked at the source code to see what branches have been missed. We noticed that we missed covering three parts of this code. The thing that we had to add in was a test to ensure the nullNotPermitted parameter check was working. Thus, the calculateColumnTotalForNullValues test was created. We also had to cover the if statement in the for loop that checked for null values in the data. To test this, we created a test that adds a null value to the Values2D data called calculateColumnTotalForTwoValuesWithNullValue. These new tests increased our branch coverage to 81.2%. However, there was what seemed to be unreachable code in this method (the second for loop) that we could not cover with tests which in turn reduced the total branch and line coverage for DataUtilities that we could obtain.

## 4.4 DataUtilities calculateColumnTotal(Values2D data, int column, int[] validRows)

This is an override method that was not tested during Assignment 2. To begin testing this method, similar tests to calculateColumnTotal(Values2D data, int column) were created while allowing for all valid rows. After creating these tests, we looked at the method inside of DataUtilities to determine what branches we missed. There were a few branches that needed invalid rows added into the validRows array so we had to create some tests to test these branches. There was also a few lines in the method that were unreachable. The first if that checks to see if total > 0 was not possible to test as the line before sets total to 0. It is also important to note that in the calculateRowTotal(Values2D data, int column, int[] validRows) method, this line was different. Instead of the total being inside of the if loop, it checked if colCount < 0 and would also set total to a different value. This was odd as both of these calsses should be similar and no differences like this should be present.

## 4.5 DataUtilities equal(double[][] a, double[][] b)

This method was not been tested during Assignment 2. To begin, we first read through the documentation on what the method should do. After we understood how it was intended to work, we looked at the source code to see how the function had been implemented; the method was basically taking in two arrays and then comparing them to check if they are equal. We noticed that there were 12 branches, so we created 8 test cases to test all 12 branches, thus we ended up reaching 100% statement, branch and method coverage for equal(double[][] a, double[][] b). Overall, after adding the test for this method we ended up reaching 87.5% statement coverage, 81.2% branch coverage and 90% method coverage.

# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

## 5.1 Range Coverage

### 5.1.1 Before

Method coverage:
<img src="coverage_screenshots/RangeMethodBefore.png" alt="coverage_screenshots/RangeMethodBefore.png"/>

Branch coverage:
<img src="coverage_screenshots/RangeBranchBefore.png" alt="coverage_screenshots/RangeBranchBefore.png"/>

Statement coverage:
<img src="coverage_screenshots/RangeLineBefore.png" alt="coverage_screenshots/RangeLineBefore.png"/>

### 5.1.2 After

Method coverage:
<img src="coverage_screenshots/RangeMethodAfter.png" alt="coverage_screenshots/RangeMethodAfter.png"/>

Branch coverage:
<img src="coverage_screenshots/RangeBranchAfter.png" alt="coverage_screenshots/RangeBranchAfter.png"/>

Statement coverage:
<img src="coverage_screenshots/RangeLineAfter.png" alt="coverage_screenshots/RangeLineAfter.png"/>

## 5.2 DataUtilities Coverage

### 5.2.1 Before

Method coverage:
<img src="coverage_screenshots/DataUtilitiesMethodBefore.png" alt="coverage_screenshots/DataUtilitiesMethodBefore.png"/>

Branch coverage:
<img src="coverage_screenshots/DataUtilitiesBranchBefore.png" alt="coverage_screenshots/DataUtilitiesBranchBefore.png"/>

Statement coverage:
<img src="coverage_screenshots/DataUtilitiesLineBefore.png" alt="coverage_screenshots/DataUtilitiesLineBefore.png"/>

### 5.2.2 After

Method coverage:
<img src="coverage_screenshots/DataUtilitiesMethodAfter.png" alt="coverage_screenshots/DataUtilitiesMethodAfter.png"/>

Branch coverage:
<img src="coverage_screenshots/DataUtilitiesBranchAfter.png" alt="coverage_screenshots/DataUtilitiesBranchAfter.png"/>

Statement coverage:
<img src="coverage_screenshots/DataUtilitiesLineAfter.png" alt="coverage_screenshots/DataUtilitiesLineAfter.png"/>

# 6 Pros and Cons of coverage tools used and Metrics you report

The coverage tool that we used for this lab was called Eclipse EclEmma. It was nice that the tool was built into eclipse which made it very easy to implement and use. We also found that it was useful to use when examining the classes that tests were being made for as it highlighted each line with different colours based on what has been covered by tests and what has been missed. However, it seemed like some code that should be covered by our current tests in the DataUtilities class was not actually being covered after running this tool. After, we found out that EclEmma has trouble dealing with abstract classes and instead will mark it as being missed. As well, the tool did not have a condition coverage, so we had to change that type of coverage to be a method coverage instead.

The types of coverages used by our group were:

- Line Coverage
- Branch Coverage
- Method Coverage

# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation

Coverage-based test generation allowed us to be more efficient when designing test cases. We noticed when we used requirements-based test generation, sometimes we would have many tests covering the same lines of code and branches! Since we were doing black-box testing, we had no way of knowing this. However, when working with white-box testing and coverage-based generation, we were able to be more efficient when designing the tests.

Although our tests were more efficient when using coverage-based generation, our test creation process was slowed down. Rather than just reading the documentation for each method, we had to read through and understand the source code in order to write good quality tests for it.

# 8 A discussion on how the team work/effort was divided and managed

We began by meeting and setting up our environment for this assignment together. We then ran the coverage tools together to ensure we all had the same values and understood what the results meant. After this, we divided up the work into 4 sections. The first section was creating the manual data-flow charts. The second section was updating the test suite for the Range tests that had been developed in Assignment 2. The third section was writing tests for the methods that had not been tested in Assignment 2. The final section was updating the tests for DataUtilities from Assignment 2. Each team member began working on one section, and updated the rest of the team with their progress. This way, we could all ensure we had something to work on, and that the workload was equally balanced. When one team member was finished with their section, they would notify the rest of the team, and then start working in another section where someone else was struggling.

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

During this lab, our group encountered a few challenges that we had to overcome. The first difficulty we faced was setting up the external libraries for the lab. After importing all the libraries given to us by the lab, it seemed that one was missing and caused all of our code to not run properly. The library that was missing was the hamcrest-library as the file we had only containted the hamcrest-core. To fix this, we had to copy over the old hamcrest-library from lab 2. Another difficulty we faced was close to the end of testing. There were parts in the code of DataUtilities that were not being covered even though it seemed as if nothing was stopping them from running. We later found out that EclEmma could not tell that we could not instantiate this class as it was abstract. It instead thought we were not covering it in our tests and marked it red after running the coverage tool. One more difficulty we faced was reaching 90% statement coverage for DataUtilities. For the methods calculateColumnTotal(Values2D data, int column), calculateRowTotal(Values2D data, int row) and getCumulativePercentages(KeyedValues data) the second for loop was not reachable as to reach the second for loop the row and column values have to be less than zero which is not possible. Thus we were not able to reach 90% statment coverage for DataUtilities instead we ended up with 87.5%.

# 10 Comments/feedback on the lab itself

This lab was a good way to introduce us to whitebox unit testing while allowing us to try it out on a familiar project. It allowed us to implement the code coverage techniques that we have been learning in an environment that we have already explored. This let us focus on the main takeaways of the lab instead of having to read a bunch of new code and figure out what it does. However, it would have been useful to contain all the libraries that were needed as it seemed that one was missing and we had to figure out why the code wouldn't run on our own.
